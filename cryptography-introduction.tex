\section{Introductory concepts}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% *** FIRST SUB-SECTION ***
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Hash functions}
A hash function is a fuction that maps an arbitrary long input string to a fixed
length output string. Let $h$ refer to an hash function of length $n$:

\[
  h\colon \{0,1\}^* \to \{0,1\}^n
\]

$m$ is usually called ``the message'', while $d$ is usually called ``the digest``
and it can be seen as a compact representation of m. The length of $d$ is the

Hash functions are usually used to provide data integrity and they're also used to
length of the hash.
construct other cryptographic primitives such as MACs and digital signatures.

\subsubsection{Desired properties}
An hash function should ideally meet these properties:
\begin{itemize}
  \item \textbf{Computational efficiency}: given m, it must be easy to compute ${d=h(m)}$
  \item \textbf{Preimage resistance} (also called \textbf{one-way property}):
  given ${d=h(m)}$, it must be computationally infeasible computing $m$ ($m$ is the
  preimage)
  \item \textbf{Weak collision resistance} (also called
  \textbf{2\textsuperscript{nd} preimage resistance}): given $m_1$ and ${d_1=h(m_1)}$,
  it must be computationally infeasible finding a $m_2 \neq m_1$ so that ${h(m_2)=d_1}$
  \item \textbf{Strong collision resistance}: it must be computationally infeasible
  finding paris of distinct and colliding messages. Two messages $m_1\neq m_2$
  collide when ${h(m_1)=h(m_2)}$.
  \item \textbf{Avalanche effect}: changing a single bit of $m$ should cause every
  bit of ${d=h(m)}$ to change with probability ${P=0.5}$
\end{itemize}

\subsubsection{Examples of hash functions}
\begin{itemize}
  \item \textbf{MD5}: published in 1991, it's a 128-bit hash function that was
  used for file integrity checks. Today it's considered unsecure and it shouldn't
  be used anymore.
  \item \textbf{Secure Hash algorithm 1 (SHA-1)}: 160-bit hash function that was
  used in SSL and TLS implementations. Today is considered unsecure and it's
  deprecated.
  \item \textbf{SHA-2}: family of SHA functions which includes SHA-256, SHA-384
  and SHA-512. SHA-256 is currently used in several parts of the Bitcoin network.
  \item \textbf{SHA-3}: latest family of SHA functions, it is a NIST-standardized
  version of Keccak, which uses a new approach called ``sponge construction''
  instead of the Merkle-Damgard transformation previously used. This family
  includes SHA3-256, SHA3-384 and SHA3-512.
\end{itemize}

\subsubsection{Design of SHA-256}

\subsubsection{Message Authentication Codes (MACs)}
A MAC is an hash function which uses a key and which can therefore be used to
provide both integrity and authentication (proof of origin). Authentication is
based on a key pre-shared between the sender and the receiver. The receiver can
verify both integrity and authentication of a message by computing the MAC function
of the message and comparing it with the one received from the sender: if they are the
same then integrity and authentication are confirmed (note that it is assumed that
only the sender and the receiver know the key).

MAC functions can be constructed using block ciphers or hash functions:
\begin{itemize}
  \item in the first approach, block ciphers are used in the Cipher block chaining mode (CBC mode):
  the MAC of a message will be the output of the last round of the CBC operation.
  The length of MAC in this case is the same as the block length of the block cipher
  used to generate it.
  \item In the second approach they key is hashed with the message using a certain
  construction scheme. The most simple ones are \emph{suffix-only} and
  \emph{prefix-only}, which however are weak and vulnerable:
  \begin{itemize}
    \item suffix-only: ${d=MAC_k(m)=h(m|k)}$, where $h$ is an hash function
    \item prefix-only: ${d=MAC_k(m)=h(k|m)}$, where $h$ is an hash function
  \end{itemize}
\end{itemize}





\subsection{Digital signature}
Digital signatures are used to associate a message with the entity from which the
message has been originated. They provide the same service as MACs (authentication
and non-repudiation) plus the non-repudiation.

Digital signature is based on public key cryptography: Alice can sign a message
by encrypting it using its private key. Usually however, for efficiency and security
reasons, Alice doesn't encrypt the message but its digest (hash of the message).
Figure \ref{fig:digital-signature} shows how a generical digital signature function
works.

An example of digital signature algorithms are RSA and ECDSA.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=1\linewidth]{img/digital-signature.png}
	\caption{digital signature signing and verification scheme}
	\label{fig:digital-signature}
\end{figure}





\subsection{Elliptic Curve Digital Signature Algorithm (ECDSA)}
ECDSA is a variant of the Digital Signature Algorithm (DSA) which uses elliptic
curve cryptography.

\subsubsection{Key pair generation}
\begin{enumerate}
  \item Define an elliptic curve $E$ with modulus $P$, coefficients $a$ and $b$ and a
  generator point $A$ that forms a cyclic group of order $p$, with $p$ prime
  \item Choose a random integer $d$ so that ${0 < d < q}$
  \item Compute the public key $B$ so that ${B = d  A}$
\end{enumerate}
The public key is the sextuple ${K_{pb} = (p,a,b,q,A,B)}$, while the private key
is the value of $d$ randomly chosen in Step 2: ${K_{pr} = d}$

\subsubsection{Signing a message}
\begin{enumerate}
  \item Choose an ephemeral key $K_e$, where ${0 < K_e < q}$.
  It should be ensured that $K_e$ is truly random and no two signatures have the same key
  because otherwise the private key can be calculated
  \item Compute ${R = K_e A}$
  \item Initialize a variable $r$ with the x coordinate value of the point $R$
  \item The signature on the message $m$ can be calculated as follow:
  \[{S=(h(m)+d r)K_e^{-1}\bmod q}\]
  where $h(m)$ is the hash of the message $m$. The signature is the pair ${(S,r)}$.
\end{enumerate}

\subsubsection{Signature verification}
A signature can be verified as follow:
\begin{enumerate}
  \item Compute ${w=S^{-1}\bmod q}$
  \item Compute ${u_1=w  h(m)\bmod q}$
  \item Compute ${u_2=w  r \bmod q}$
  \item Calculate the point ${P=u_1  A + u_2  B}$
  \item The signature ${(S,r)}$ is accepted as a valid signature only if:
   \[{X_P=r \bmod q}\]
   where $X_P$ is the x-coordinate of the point P calculated in Step 4
\end{enumerate}











%%%%%%%%%%%%%%%%%%%%%%%%%%%
% *** SECOND SUB-SECTION ***
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Distributed systems}
\subsubsection{What is a distributed system}
Blockchain at its core is basically a distributed system, therefore it is essential
to understand distributed systems before understanding Blockchain.

A distributed system is a network that consists of autonomous nodes, connected
using a distribution middleware, which act in a coordinated way (passing message
to each other) in order to achieve a common outcome and that can be seen by the
user as a single logical platform.

A node is basically a computer that can be seen as an individual player inside
the distributed system and it can be honest, faulty or malicious. Nodes that
have an arbitrary behavior (which can be malicious) are called \emph{Byzantine nodes}.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.6\linewidth]{img/distributed-system.png}
	\caption{design of a distributed system. N4 is a Byzantine node while L1 is a
  broken/slow network link}
	\label{fig:distributed-system}
\end{figure}

The main challenge in a distributed system is the fault tollerance: even if some
of the nodes fault or links break, the system should tollerate this and should
continue to work correctly. There are essentially two types of fault: a simple node
crash or the exhibition of malicious or inconsistent behavior arbitrarily. The
second case is the most difficult to deal with and it's called \emph{Byzantine
fault}. In order to achieve fault tolerance, replication is usually used.

Desired properties of a distributed system are the following:
\begin{itemize}
  \item \textbf{Consistency}: all the nodes have the same lates available copy of
  the data. It is usually achieved through consensus algorithms which ensure that
  all nodes have the same copy of the data
  \item \textbf{Availability}: the system is always working and responding to the
  input requests without any failures
  \item \textbf{Partition tolerance}: if a group of nodes fails the distributed
  system still continues to operate correctly
\end{itemize}
There is however a theorem, the \emph{CAP theorem}, which states (and proves)
that a distributed system cannot have all these three properties at the same time.
In particular, the theorem states that in the presence of a network partition (due
for example to a link failure) one has to choose between consistency and availability.


\subsubsection{The Byzantine Generals Problem (BGP)}
The Byzantine Generals Problem (BGP) is a problem described by Leslie Lamport
\cite{lamport1982byzantine} in which a group of generals, each one leading a portion
on the Byzantine army, are surrounding a city and they have to formulate a plan
for attacking it (simplifying, they have to decide wheter to attack or retreat
from the city). Their only communication way is the messenger and they have to
agree on a common decision. The issue is that some of the generals may be
traitors trying to prevent the loyal generals from reaching an agreement by
communicating a misleading message. The generals need an algorithm to guarantee
that all the generals agree on the same plan (attack or retreat) regardless of what
traitors generals do. Loyal generals will always do what the algorithm says they
should, while the traitors may do anything they wish.

As an analogy with distributed systems:
\begin{itemize}
  \item generals can be considered as nodes
  \item traitors can be considered Byzantine nodes
  \item the messenger can be seen as the channels of communication between the generals.
\end{itemize}

\subsubsection{Consensus}
Consensus is the process of agreement between untrusted nodes on a data value.
When the involved nodes are only two it's really easy to achieve consensus, while
in a distributed system with more than two nodes it is really hard (in this case
the process of achieving consensus is called \emph{distributed consensus}).

A consensus mechanism must meet these requirements:
\begin{itemize}
  \item \textbf{Agreement}: all the nodes must agree on the same value
  \item \textbf{Termination}: the execution of the consensus process must come
  to an end and the nodes have to reach a decision
  \item \textbf{Validity}: the agreed value must have been proposed by at least
  one honest node
  \item \textbf{Fault tolerance}: the consensus algorithm must be able to run even
  in the presence of one or more Byzantine (faulty or malicious) nodes
  \item \textbf{Integrity}: the nodes make decisions only once in a single
  consensus cycle (in a single cycle a node cannot make the decision more than once).
\end{itemize}
